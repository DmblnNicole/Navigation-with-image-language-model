{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install segments-ai\n",
    "from segments import SegmentsClient, SegmentsDataset\n",
    "from segments.utils import get_semantic_bitmap\n",
    "import cv2\n",
    "import numpy as np\n",
    "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# Initialize a SegmentsDataset from the release file\n",
    "client = SegmentsClient('06bcb58a22ed6e6b10f075fc2bf8016ffcfda3b6')\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint='checkpoints/sam_vit_h_4b8939.pth').to(device='cuda')\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitmap2image(semantic_bitmap) -> Image:\n",
    "    A = np.asarray(semantic_bitmap, dtype=np.uint8)\n",
    "    image = np.zeros((A.shape[0], A.shape[1], 3), dtype=np.uint8)\n",
    "    image[:,:,0] = A*255\n",
    "    image[:,:,1] = A*255\n",
    "    image[:,:,2] = A*255\n",
    "    image = Image.fromarray(image, 'RGB')\n",
    "    return image\n",
    "\n",
    "def image2bitmap(image : Image, dtype=np.uint8):\n",
    "    image = np.asarray(image, dtype=dtype)\n",
    "    bitmap = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "    bitmap = image[:,:,0]\n",
    "    return bitmap\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    return mask_image\n",
    "\n",
    "def combine(image : Image, semantic_mask : Image) -> Image:\n",
    "    fig = Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.gca()\n",
    "    ax.imshow(image)\n",
    "    mask = show_mask(image2bitmap(semantic_mask, dtype=np.bool_), plt)\n",
    "    ax.imshow(mask)\n",
    "    ax.axis('off')\n",
    "    canvas.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi() \n",
    "    img = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8).reshape(int(height), int(width), 3)\n",
    "    img = Image.fromarray(img, 'RGB')\n",
    "    return img\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ground truth for dirt paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 82/82 [00:00<00:00, 325.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 82 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:32<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "release2 = client.get_release('mcummins/Hike2', 'v0.2') \n",
    "dataset2 = SegmentsDataset(release2, labelset='ground-truth', filter_by=['reviewed'])\n",
    "road_dir = []\n",
    "\n",
    "for sample in tqdm(dataset2):\n",
    "    semantic_bitmap = get_semantic_bitmap(sample['segmentation_bitmap'], sample['annotations'])\n",
    "    dir = 'GT_masks/' + sample['name']\n",
    "    road_dir.append(sample['name'])\n",
    "    mask = bitmap2image(semantic_bitmap)\n",
    "    mask.save(dir, format='png')\n",
    "    illustration = combine(sample['image'], mask)\n",
    "    illustration.save('GT/'+sample['name'], format='png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ground truth for forest floors and concrete roads using SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 205/205 [00:11<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 205 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [01:40<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "gt = os.listdir('GT_masks')\n",
    "\n",
    "release = client.get_release('mcummins/Hike', 'V0.5') \n",
    "dataset = SegmentsDataset(release, labelset='ground-truth', filter_by=['reviewed'])\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    \n",
    "    if sample['name'] not in road_dir: \n",
    "\n",
    "        points = []\n",
    "        name = sample['name']\n",
    "        image = sample['image']\n",
    "        for ann in sample['annotations']:\n",
    "            points.append(ann['points'])\n",
    "        points = np.array(points)\n",
    "        points = points.reshape((points.shape[0], points.shape[2]))\n",
    "\n",
    "        predictor.set_image(np.asarray(image))\n",
    "        input_point = points\n",
    "        input_label = np.ones(points.shape[0])\n",
    "\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        \n",
    "        mask = bitmap2image(masks[0])\n",
    "        dir = 'GT_masks/' + sample['name']\n",
    "        mask.save(dir, format='png')\n",
    "        illustration = combine(image, mask)\n",
    "        illustration.save('GT/'+sample['name'], format='png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
